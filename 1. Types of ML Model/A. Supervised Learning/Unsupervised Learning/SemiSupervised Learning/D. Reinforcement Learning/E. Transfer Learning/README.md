# A. Supervised Learning
### Regression: Predicts continuous outcomes (e.g., Linear Regression, Ridge, Lasso).
#### Regression: Predicting house prices based on features like size, location, and number of rooms.
###### Example: A model estimates a house will sell for $250,000.
### Classification: Predicts categorical labels (e.g., Logistic Regression, SVM, Decision Trees, Neural Networks).
#### Classification: Identifying emails as spam or not spam.
##### Example: A model marks an email as spam based on keywords and patterns.

# B. Unsupervised Learning
### Clustering: Groups data (e.g., K-Means, DBSCAN, Hierarchical Clustering).
##### Example: A store clusters buyers into "budget shoppers" and "luxury shoppers" based on purchase history.

### Dimensionality Reduction: Reduces feature space (e.g., PCA, t-SNE, UMAP).
##### Example: Reducing thousands of customer preferences to a few key insights.

# C. Semi-Supervised Learning
### Combines labeled and unlabeled data to improve accuracy.
##### Example: A healthcare app uses a small number of labeled X-rays (diseased/healthy) and a large number of unlabeled ones to predict disease in new X-rays.

# D. Reinforcement Learning
### Trains models to make decisions in dynamic environments (e.g., Q-Learning, Deep Q-Networks).
##### Example: Training a robot to navigate a maze by rewarding it for reaching the exit and penalizing it for hitting walls.

# E. Transfer Learning
### Leverages pre-trained models to fine-tune for specific tasks (e.g., BERT, ResNet).
##### Example: Using a model trained to identify dogs and cats to distinguish between lions and tigers with minimal additional training.